#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EdgeTTSæ’ä»¶æµ‹è¯•è„šæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰
åŸºäºtestedgettsapi.pyçš„APIé…ç½®è¿›è¡Œæµ‹è¯•
"""

import os
import sys
import tempfile
import time

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tools.text_to_speech import TextToSpeechTool
from provider.edgetts_provider import EdgeTTSProvider

class MockRuntime:
    """æ¨¡æ‹ŸDifyæ’ä»¶è¿è¡Œæ—¶ç¯å¢ƒ"""
    def __init__(self):
        # ä½¿ç”¨testedgettsapi.pyä¸­çš„é…ç½®
        self.credentials = {
            "api_key": "zhouhuizhou",  # æ¥è‡ªtestedgettsapi.py
            "base_url": "https://edgettsapi.duckcloud.fun/v1"  # æ¥è‡ªtestedgettsapi.py
        }

class MockSession:
    """æ¨¡æ‹ŸDifyæ’ä»¶ä¼šè¯ç¯å¢ƒ"""
    def __init__(self):
        pass

def test_provider_validation():
    """æµ‹è¯•Providerè®¤è¯éªŒè¯åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•EdgeTTS Providerè®¤è¯éªŒè¯...")
    
    provider = EdgeTTSProvider()
    
    try:
        # æµ‹è¯•æœ‰æ•ˆå‡­æ®
        valid_credentials = {
            "api_key": "zhouhuizhou",
            "base_url": "https://edgettsapi.duckcloud.fun/v1"
        }
        provider._validate_credentials(valid_credentials)
        print("âœ… Providerè®¤è¯éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ Providerè®¤è¯éªŒè¯å¤±è´¥: {str(e)}")
        return False

def test_tts_tool():
    """æµ‹è¯•TTSå·¥å…·åŠŸèƒ½"""
    print("\nğŸµ æµ‹è¯•EdgeTTSæ–‡æœ¬è½¬è¯­éŸ³å·¥å…·...")
    
    # åˆ›å»ºå·¥å…·å®ä¾‹
    runtime = MockRuntime()
    session = MockSession()
    tool = TextToSpeechTool(runtime=runtime, session=session)
    
    # æµ‹è¯•å‚æ•°ï¼ˆåŸºäºtestedgettsapi.pyçš„å‚æ•°ï¼‰
    test_parameters = {
        "input_text": "è¿™æ˜¯ä¸€ä¸ªEdgeTTSæ’ä»¶æµ‹è¯•ï¼Œæµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½ã€‚æ¬¢è¿ä½¿ç”¨EdgeTTSæ’ä»¶ï¼",
        "voice": "zh-CN-XiaoxiaoNeural",
        "model": "tts-1",
        "speed": 1.0,
        "response_format": "mp3"
    }
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_parameters['input_text']}")
    print(f"ğŸµ è¯­éŸ³æ¨¡å‹: {test_parameters['voice']}")
    print(f"âš¡ è¯­é€Ÿ: {test_parameters['speed']}x")
    print(f"ğŸ“ æ ¼å¼: {test_parameters['response_format']}")
    
    try:
        # æ‰§è¡Œæµ‹è¯•
        messages = []
        audio_file_path = None
        audio_blob = None
        
        for message in tool._invoke(test_parameters):
            messages.append(message)
            
            # æ‰“å°æ–‡æœ¬æ¶ˆæ¯
            if hasattr(message, 'type') and str(message.type) == 'MessageType.TEXT':
                if hasattr(message, 'message') and hasattr(message.message, 'text'):
                    print(f"ğŸ“ {message.message.text}")
            
            # å¤„ç†éŸ³é¢‘æ¶ˆæ¯
            elif hasattr(message, 'type') and str(message.type) == 'MessageType.BLOB':
                if hasattr(message, 'message') and hasattr(message.message, 'blob'):
                    audio_blob = message.message.blob
                    print(f"ğŸµ æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œå¤§å°: {len(audio_blob)} å­—èŠ‚")
                    
                    # æ£€æŸ¥å…ƒæ•°æ®
                    if hasattr(message, 'meta') and message.meta:
                        filename = message.meta.get('filename', 'test_audio.mp3')
                        local_path = message.meta.get('local_path')
                        file_size = message.meta.get('file_size', len(audio_blob))
                        mime_type = message.meta.get('mime_type', 'audio/mp3')
                        
                        print(f"ğŸ“„ æ–‡ä»¶å: {filename}")
                        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                        print(f"ğŸ·ï¸ MIMEç±»å‹: {mime_type}")
                        
                        if local_path:
                            print(f"ğŸ’¾ æœ¬åœ°è·¯å¾„: {local_path}")
                            audio_file_path = local_path
                            
                            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                            if os.path.exists(local_path):
                                actual_size = os.path.getsize(local_path)
                                print(f"âœ… æ–‡ä»¶å·²ä¿å­˜ï¼Œå®é™…å¤§å°: {actual_size} å­—èŠ‚")
                            else:
                                print(f"âš ï¸ æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨: {local_path}")
        
        print("âœ… EdgeTTSå·¥å…·æµ‹è¯•å®Œæˆ")
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        if audio_blob and len(audio_blob) > 0:
            print(f"ğŸ‰ æµ‹è¯•æˆåŠŸï¼éŸ³é¢‘æ•°æ®å¤§å°: {len(audio_blob)} å­—èŠ‚")
            if audio_file_path:
                print(f"ğŸ“ éŸ³é¢‘æ–‡ä»¶ä½ç½®: {audio_file_path}")
            return True, audio_file_path
        else:
            print("âŒ æœªç”ŸæˆéŸ³é¢‘æ•°æ®")
            return False, None
            
    except Exception as e:
        print(f"âŒ TTSå·¥å…·æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False, None

def test_different_voices():
    """æµ‹è¯•ä¸åŒè¯­éŸ³æ¨¡å‹"""
    print("\nğŸ­ æµ‹è¯•ä¸åŒè¯­éŸ³æ¨¡å‹...")
    
    voices = [
        ("zh-CN-XiaoxiaoNeural", "æ™“æ™“ï¼ˆä¸­æ–‡å¥³å£°ï¼‰"),
        ("zh-CN-YunxiNeural", "äº‘å¸Œï¼ˆä¸­æ–‡ç”·å£°ï¼‰"),
        ("zh-CN-XiaoyiNeural", "æ™“ä¼Šï¼ˆä¸­æ–‡å¥³å£°ï¼‰"),
        ("zh-CN-YunjianNeural", "äº‘å¥ï¼ˆä¸­æ–‡ç”·å£°ï¼‰")
    ]
    
    runtime = MockRuntime()
    session = MockSession()
    tool = TextToSpeechTool(runtime=runtime, session=session)
    
    success_count = 0
    
    for voice_id, voice_name in voices:
        print(f"\nğŸµ æµ‹è¯•è¯­éŸ³: {voice_name} ({voice_id})")
        
        test_parameters = {
            "input_text": f"ä½ å¥½ï¼Œæˆ‘æ˜¯{voice_name}ï¼Œè¿™æ˜¯è¯­éŸ³æµ‹è¯•ã€‚",
            "voice": voice_id,
            "model": "tts-1",
            "speed": 1.0,
            "response_format": "mp3"
        }
        
        try:
            audio_generated = False
            for message in tool._invoke(test_parameters):
                if hasattr(message, 'type') and str(message.type) == 'MessageType.BLOB':
                    if hasattr(message, 'message') and hasattr(message.message, 'blob'):
                        audio_generated = True
                        print(f"âœ… {voice_name} æµ‹è¯•æˆåŠŸï¼ŒéŸ³é¢‘å¤§å°: {len(message.message.blob)} å­—èŠ‚")
                        break
            
            if audio_generated:
                success_count += 1
            else:
                print(f"âŒ {voice_name} æµ‹è¯•å¤±è´¥ï¼šæœªç”ŸæˆéŸ³é¢‘")
                
        except Exception as e:
            print(f"âŒ {voice_name} æµ‹è¯•å¤±è´¥: {str(e)}")
    
    print(f"\nğŸ“Š è¯­éŸ³æµ‹è¯•ç»“æœ: {success_count}/{len(voices)} æˆåŠŸ")
    return success_count == len(voices)

def test_speed_control():
    """æµ‹è¯•è¯­é€Ÿæ§åˆ¶"""
    print("\nâš¡ æµ‹è¯•è¯­é€Ÿæ§åˆ¶...")
    
    speeds = [0.5, 1.0, 1.5, 2.0]
    runtime = MockRuntime()
    session = MockSession()
    tool = TextToSpeechTool(runtime=runtime, session=session)
    
    success_count = 0
    
    for speed in speeds:
        print(f"\nâš¡ æµ‹è¯•è¯­é€Ÿ: {speed}x")
        
        test_parameters = {
            "input_text": f"è¿™æ˜¯{speed}å€é€Ÿçš„è¯­éŸ³æµ‹è¯•ã€‚",
            "voice": "zh-CN-XiaoxiaoNeural",
            "model": "tts-1",
            "speed": speed,
            "response_format": "mp3"
        }
        
        try:
            audio_generated = False
            for message in tool._invoke(test_parameters):
                if hasattr(message, 'type') and str(message.type) == 'MessageType.BLOB':
                    if hasattr(message, 'message') and hasattr(message.message, 'blob'):
                        audio_generated = True
                        print(f"âœ… {speed}xè¯­é€Ÿæµ‹è¯•æˆåŠŸï¼ŒéŸ³é¢‘å¤§å°: {len(message.message.blob)} å­—èŠ‚")
                        break
            
            if audio_generated:
                success_count += 1
            else:
                print(f"âŒ {speed}xè¯­é€Ÿæµ‹è¯•å¤±è´¥ï¼šæœªç”ŸæˆéŸ³é¢‘")
                
        except Exception as e:
            print(f"âŒ {speed}xè¯­é€Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
    
    print(f"\nğŸ“Š è¯­é€Ÿæµ‹è¯•ç»“æœ: {success_count}/{len(speeds)} æˆåŠŸ")
    return success_count == len(speeds)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹EdgeTTSæ’ä»¶å®Œæ•´æµ‹è¯•...")
    print("=" * 50)
    
    # æµ‹è¯•ç»“æœç»Ÿè®¡
    test_results = []
    
    # 1. æµ‹è¯•Providerè®¤è¯
    provider_result = test_provider_validation()
    test_results.append(("Providerè®¤è¯éªŒè¯", provider_result))
    
    # 2. æµ‹è¯•åŸºç¡€TTSåŠŸèƒ½
    tts_result, audio_path = test_tts_tool()
    test_results.append(("åŸºç¡€TTSåŠŸèƒ½", tts_result))
    
    # 3. æµ‹è¯•ä¸åŒè¯­éŸ³æ¨¡å‹
    voices_result = test_different_voices()
    test_results.append(("å¤šè¯­éŸ³æ¨¡å‹", voices_result))
    
    # 4. æµ‹è¯•è¯­é€Ÿæ§åˆ¶
    speed_result = test_speed_control()
    test_results.append(("è¯­é€Ÿæ§åˆ¶", speed_result))
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 50)
    
    success_count = 0
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            success_count += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {success_count}/{len(test_results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if success_count == len(test_results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼EdgeTTSæ’ä»¶åŠŸèƒ½æ­£å¸¸ã€‚")
        if audio_path:
            print(f"ğŸµ ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥ã€‚")
    
    return success_count == len(test_results)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)